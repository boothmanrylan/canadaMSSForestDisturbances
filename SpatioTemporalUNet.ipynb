{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCiujw1uhHVfUSSCigLbY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/canadaMSSForestDisturbances/blob/main/SpatioTemporalUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "nK2Okp4_y0rr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtIfE64DyuEr"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "PROJECT_ID = \"api-project-269347469410\"\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import saved_model_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm"
      ],
      "metadata": {
        "id": "4lQ9lMihzB0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "g2ZY4Mub0Ay3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OUTPUTS = 10\n",
        "EXPORT_HEIGHT = 512\n",
        "EXPORT_WIDTH = 512\n",
        "HEIGHT = 256\n",
        "WIDTH = 256\n",
        "\n",
        "# TODO: DEM will make an uneven number of bands that doesn't split into current/past as the DEM wont have changed\n",
        "BANDS = [\n",
        "    'nir', 'red_edge', 'red', 'green',\n",
        "    'tca', 'ndvi',\n",
        "    'historical_nir', 'historical_red_edge', 'historical_red', 'historical_green',\n",
        "    'historical_tca', 'historical_ndvi'\n",
        "]\n",
        "METADATA = ['doy', 'ecozone'] # , 'lat', 'lon']\n",
        "NUM_INPUTS = len([b for b in BANDS if \"historical\" not in b])\n",
        "LABEL_BAND = 'label'\n",
        "\n",
        "MAX_DOY = 110\n",
        "NUM_ECOZONES = 10  # there are only seven represented in the sanity test dataset\n",
        "\n",
        "# Data Config\n",
        "BUCKET = 'rylan-mssforestdisturbances'\n",
        "BASE_PATH = f'gs://{BUCKET}/scratch/test_export/ecozone*/'\n",
        "TEST_PATTERN = os.path.join(BASE_PATH, '*-00000-of-*.tfrecord.gz')\n",
        "TRAIN_PATTERN = os.path.join(BASE_PATH, '*-000[0-9][1-9]-of*.tfrecord.gz')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER = 100\n",
        "\n",
        "SUBSET_SIZE = 100\n",
        "\n",
        "# Model Config\n",
        "FILTERS = [32, 64, 128, 256]\n",
        "KERNELS = [7, 5, 3, 3]\n",
        "DILATION_RATES = [1, 1, 2, 4]\n",
        "UPSAMPLE_FILTERS = 3\n",
        "METADATA_FILTERS = 32\n",
        "OUTPUT_KERNEL = 3\n",
        "MODEL_CONFIG = list(zip(FILTERS, KERNELS, DILATION_RATES))\n",
        "\n",
        "TWO_DOWNSTACKS = True\n",
        "INCLUDE_HISTORICAL = True\n",
        "INCLUDE_METADATA = True\n",
        "\n",
        "if not (TWO_DOWNSTACKS and INCLUDE_HISTORICAL):\n",
        "    BANDS = [b for b in BANDS if \"historical\" not in b]\n",
        "\n",
        "RNG = tf.random.Generator.from_seed(42, alg=\"philox\")\n",
        "\n",
        "# AI Platform Hosting Config\n",
        "REGION = \"us-central1\"\n",
        "MODEL_DIR = f\"gs://{BUCKET}/scratch/models/\"\n",
        "EEIFIED_DIR = f\"gs://{BUCKET}/scratch/eeified_models/test_model_hosting/\"\n",
        "MODEL_NAME = \"test_model\"\n",
        "VERSION_NAME = \"v0\""
      ],
      "metadata": {
        "id": "KzYCNhqYzp5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "SDNWi739r1gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_FEATURES = {\n",
        "    b: tf.io.FixedLenFeature(\n",
        "        shape=(EXPORT_HEIGHT, EXPORT_WIDTH),\n",
        "        dtype=tf.float32\n",
        "    )\n",
        "    for b in BANDS\n",
        "}\n",
        "\n",
        "LABEL_FEATURES = {\n",
        "    LABEL_BAND: tf.io.FixedLenFeature(\n",
        "        shape=(EXPORT_HEIGHT, EXPORT_WIDTH),\n",
        "        dtype=tf.int64\n",
        "    )\n",
        "}\n",
        "\n",
        "METADATA_FEATURES = {\n",
        "    m: tf.io.FixedLenFeature(shape=1, dtype=tf.int64)\n",
        "    for m in METADATA\n",
        "}\n",
        "\n",
        "\n",
        "def parse(example):\n",
        "    x = tf.io.parse_single_example(example, IMAGE_FEATURES)\n",
        "    x = tf.stack([x[b] for b in BANDS], axis=-1)\n",
        "\n",
        "    y = tf.io.parse_single_example(example, LABEL_FEATURES)[LABEL_BAND]\n",
        "    y = tf.one_hot(y, NUM_OUTPUTS)\n",
        "\n",
        "    metadata = tf.io.parse_single_example(example, METADATA_FEATURES)\n",
        "    metadata = [metadata[m] for m in METADATA]\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        x = (x, *metadata)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def non_overlapping_crop(x, y):\n",
        "    assert EXPORT_HEIGHT % HEIGHT == 0\n",
        "    assert EXPORT_WIDTH % WIDTH == 0\n",
        "\n",
        "    def _crop(tensor):\n",
        "        \"\"\" based on https://stackoverflow.com/a/31530106\n",
        "        \"\"\"\n",
        "        tensor = tf.reshape(\n",
        "            tensor,\n",
        "            (EXPORT_HEIGHT // HEIGHT, HEIGHT, EXPORT_WIDTH // WIDTH, WIDTH, -1)\n",
        "        )\n",
        "        cropped = tf.experimental.numpy.swapaxes(tensor, 1, 2)\n",
        "\n",
        "        num_blocks = (EXPORT_HEIGHT // HEIGHT) * (EXPORT_WIDTH // WIDTH)\n",
        "        cropped = tf.reshape(cropped, (num_blocks, HEIGHT, WIDTH, -1))\n",
        "        return tf.data.Dataset.from_tensor_slices(cropped)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        metadata = [\n",
        "            tf.data.Dataset.from_tensor_slices(m).repeat()\n",
        "            for m in x[1:]\n",
        "        ]\n",
        "        x = x[0]\n",
        "\n",
        "    x = _crop(x)\n",
        "    y = _crop(y)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        x = tf.data.Dataset.zip((x, *metadata))\n",
        "\n",
        "    return tf.data.Dataset.zip((x, y))\n",
        "\n",
        "\n",
        "def crop(x, y, seed):\n",
        "    if INCLUDE_METADATA:\n",
        "        metadata = x[1:]\n",
        "        x = x[0]\n",
        "\n",
        "    y_shape = tf.shape(y)\n",
        "    if len(y_shape) == 2:  # add temporary channel dimension\n",
        "        y = tf.reshape(y, y_shape + (1,))\n",
        "        num_y_bands = 1\n",
        "    else:\n",
        "        num_y_bands = y_shape[-1]\n",
        "\n",
        "    y_type = y.dtype\n",
        "    desired_type = x.dtype\n",
        "    y = tf.cast(y, desired_type)\n",
        "\n",
        "    num_x_bands = tf.shape(x)[-1]\n",
        "    xy = tf.concat([x, y], -1)\n",
        "\n",
        "    target_shape = (HEIGHT, WIDTH, num_x_bands + num_y_bands)\n",
        "    xy = tf.image.stateless_random_crop(xy, target_shape, seed=seed)\n",
        "\n",
        "    x = xy[:, :, :-num_y_bands]\n",
        "\n",
        "    y = tf.squeeze(tf.cast(xy[:, :, -num_y_bands:], y_type))\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        x = (x, *metadata)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def crop_wrapper(x, y):\n",
        "    seed = RNG.make_seeds(2)[0]\n",
        "    x, y = crop(x, y, seed)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def build_dataset(tfrecord_pattern, train=True):\n",
        "    tfrecords = tf.data.Dataset.list_files(tfrecord_pattern, shuffle=train)\n",
        "    dataset = tfrecords.interleave(\n",
        "        lambda x: tf.data.TFRecordDataset(x, compression_type='GZIP').map(parse, num_parallel_calls=1),\n",
        "        cycle_length=3 * NUM_ECOZONES,\n",
        "        block_length=BATCH_SIZE // 4,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "        deterministic=not train,\n",
        "    )\n",
        "\n",
        "    dataset = dataset.cache()\n",
        "\n",
        "    if train:\n",
        "        dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
        "        dataset = dataset.map(crop_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        dataset = dataset.flat_map(non_overlapping_crop)\n",
        "\n",
        "    if train:\n",
        "        subset = []\n",
        "        for x, y in dataset.take(math.ceil(SUBSET_SIZE / BATCH_SIZE)):\n",
        "            if INCLUDE_METADATA:\n",
        "                subset.append(x[0])\n",
        "            else:\n",
        "                subset.append(x)\n",
        "        subset = tf.concat(subset, axis=0)\n",
        "\n",
        "        dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    if train:\n",
        "        return dataset, subset\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset, normalize_subset = build_dataset(\n",
        "    TRAIN_PATTERN,\n",
        "    train=True,\n",
        ")\n",
        "test_dataset = build_dataset(\n",
        "    TEST_PATTERN,\n",
        "    train=False,\n",
        ")"
      ],
      "metadata": {
        "id": "hk_KyWjMr3x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatial Model\n"
      ],
      "metadata": {
        "id": "T2T_wwEYzK0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalFusion(tf.keras.layers.Layer):\n",
        "    \"\"\" Change detection layer.\n",
        "\n",
        "    Based on Late Fusion from Maretto et al. 2021 10.1109/LGRS.2020.2986407\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv = tf.keras.layers.Conv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=(1, 1),\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "\n",
        "    def call(self, input1, input2):\n",
        "        x = tf.concat([input1, input2], -1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DownSample(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, dilation_rate, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.separable_conv2d_1 = tf.keras.layers.SeparableConv2D(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            dilation_rate=dilation_rate,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.separable_conv2d_1(x)\n",
        "        x = self.batch_norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpSample(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.transposed_conv2d_1 = tf.keras.layers.Conv2DTranspose(\n",
        "            filters=filters,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "        )\n",
        "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.transposed_conv2d_1(x)\n",
        "        x = self.batch_norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MetadataBias(tf.keras.layers.Layer):\n",
        "    \"\"\" Layer to include scalar metadata in a fully convolutional network.\n",
        "\n",
        "    Based on LSENet from Xie, Guo, and Dong 2022 10.1109/TGRS.2022.3176635\n",
        "\n",
        "    x += Dense(Concat([Dense(GlobalAvgPool(x)), Embedding(scalars)]))\n",
        "    \"\"\"\n",
        "    def __init__(self, num_outputs, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.num_outputs = num_outputs\n",
        "        self.num_inputs = self.num_outputs // 3\n",
        "\n",
        "        self.doy_embedding = tf.keras.layers.Embedding(\n",
        "            MAX_DOY,\n",
        "            self.num_inputs\n",
        "        )\n",
        "        self.ecozone_embedding = tf.keras.layers.Embedding(\n",
        "            NUM_ECOZONES,\n",
        "            self.num_inputs\n",
        "        )\n",
        "\n",
        "        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.dense1 = tf.keras.layers.Dense(self.num_inputs)\n",
        "        self.dense2 = tf.keras.layers.Dense(self.num_outputs)\n",
        "\n",
        "    def call(self, x, doy, ecozone):\n",
        "        doy_embedding = self.doy_embedding(doy)[:, 0]\n",
        "        ecozone_embedding = self.ecozone_embedding(ecozone)[:, 0]\n",
        "\n",
        "        pooled_x = self.pool(x)\n",
        "        pooled_x = self.dense1(pooled_x)\n",
        "\n",
        "        metadata = tf.concat(\n",
        "            [pooled_x, doy_embedding, ecozone_embedding],\n",
        "            axis=-1\n",
        "        )\n",
        "        metadata = self.dense2(metadata)\n",
        "        metadata = tf.reshape(metadata, (-1, 1, 1, self.num_outputs))\n",
        "\n",
        "        return x + metadata"
      ],
      "metadata": {
        "id": "SnxOLjLIaxZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_two_downstack_model(subset):\n",
        "    normalizer = tf.keras.layers.Normalization()\n",
        "    normalizer.adapt(subset)\n",
        "\n",
        "    input_layer = tf.keras.layers.Input(shape=(HEIGHT, WIDTH, 2 * NUM_INPUTS))\n",
        "    x = normalizer(input_layer)\n",
        "\n",
        "    x1 = x[:, :, :, :NUM_INPUTS]\n",
        "    x2 = x[:, :, :, NUM_INPUTS:]\n",
        "\n",
        "    down_stack_1 = [DownSample(*config) for config in MODEL_CONFIG]\n",
        "    down_stack_2 = [DownSample(*config) for config in MODEL_CONFIG]\n",
        "    up_stack = [UpSample(f, UPSAMPLE_FILTERS) for f in reversed(FILTERS)]\n",
        "\n",
        "    skips = []\n",
        "    for i, (down1, down2) in enumerate(zip(down_stack_1, down_stack_2)):\n",
        "        x1 = down1(x1)\n",
        "        x2 = down2(x2)\n",
        "        x = TemporalFusion(FILTERS[i])(x1, x2)\n",
        "        skips.append(x)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        doy_input = tf.keras.layers.Input(shape=1, dtype=tf.int64)\n",
        "        ecozone_input = tf.keras.layers.Input(shape=1, dtype=tf.int64)\n",
        "\n",
        "        metadata_bias = MetadataBias(FILTERS[-1])\n",
        "        x = metadata_bias(x, doy_input, ecozone_input)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(\n",
        "        NUM_OUTPUTS,\n",
        "        kernel_size=OUTPUT_KERNEL,\n",
        "        padding=\"same\",\n",
        "        activation=\"softmax\",\n",
        "    )(x)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        inputs = [input_layer, doy_input, ecozone_input]\n",
        "    else:\n",
        "        inputs = input_layer\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_single_downstack_model(subset):\n",
        "    if INCLUDE_HISTORICAL:\n",
        "        shape = (HEIGHT, WIDTH, 2 * NUM_INPUTS)\n",
        "    else:\n",
        "        shape = (HEIGHT, WIDTH, NUM_INPUTS)\n",
        "\n",
        "    input_layer = tf.keras.layers.Input(shape=shape)\n",
        "\n",
        "    image_normalizer = tf.keras.layers.Normalization()\n",
        "    image_normalizer.adapt(subset)\n",
        "\n",
        "    x = image_normalizer(input_layer)\n",
        "\n",
        "    down_stack = [DownSample(*config) for config in MODEL_CONFIG]\n",
        "    up_stack = [UpSample(f, UPSAMPLE_FILTERS) for f in reversed(FILTERS)]\n",
        "\n",
        "    skips = []\n",
        "    for i, down in enumerate(down_stack):\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        doy_input = tf.keras.layers.Input(shape=1)\n",
        "        ecozone_input = tf.keras.layers.Input(shape=1)\n",
        "        lat_input = tf.keras.layers.Input(shape=1)\n",
        "        lon_input = tf.keras.layers.Input(shape=1)\n",
        "\n",
        "        metadata_bias = MetadataBias(METADATA_FILTERS, FILTERS[-1])\n",
        "        x = metadata_bias(x, doy_input, ecozone_input, lat_input, lon_input)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = tf.keras.layers.Conv2DTranspose(\n",
        "        NUM_OUTPUTS,\n",
        "        kernel_size=OUTPUT_KERNEL,\n",
        "        padding=\"same\",\n",
        "        activation=\"softmax\",\n",
        "    )(x)\n",
        "\n",
        "    if INCLUDE_METADATA:\n",
        "        inputs = [input_layer, doy_input, ecozone_input, lat_input, lon_input]\n",
        "    else:\n",
        "        inputs = input_layer\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "if TWO_DOWNSTACKS:\n",
        "    model = build_two_downstack_model(normalize_subset)\n",
        "else:\n",
        "    model = build_single_downstack_model(normalize_subset)\n",
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "js_aab3ZZu4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal Model"
      ],
      "metadata": {
        "id": "BRQiXeNpQAqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(\n",
        "            units,\n",
        "            return_sequences=True,\n",
        "        )\n",
        "        self.lstm2 = tf.keras.layers.LSTM(\n",
        "            units,\n",
        "            return_sequences=True,\n",
        "        )\n",
        "        self.lstm3 = tf.keras.layers.LSTM(\n",
        "            units,\n",
        "            return_sequences=False,\n",
        "            return_state=True,\n",
        "        )\n",
        "\n",
        "    def call(self, x, initial_states=None):\n",
        "        initial_state = [None] * 3 if initial_state is None\n",
        "        x, state1 = self.lstm1(x, initial_state=initial_state[0])\n",
        "        x, state2 = self.lstm2(x, initial_state=initial_state[1])\n",
        "        x, state3 = self.lstm3(x, initial_state=initial_state[2])\n",
        "        return x, [state1, state2, state3]"
      ],
      "metadata": {
        "id": "oHKliI_cRCm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_temporal_model(units, num_inputs, num_outputs):\n",
        "    lookback_input = tf.keras.layers.Input(shape=(None, num_inputs))\n",
        "    target_input = tf.keras.layers.Input(shape=(None, num_inputs))\n",
        "    lookahead_input = tf.keras.layers.Input(shape=(None, num_inputs))\n",
        "\n",
        "    lookback, states = RecurrentBlock(units)(lookback_input)\n",
        "    target, states = RecurrentBlock(units)target_input, initial_states=states)\n",
        "    lookahead, _ = RecurrentBlock(units)(lookahead_input, initial_state=states)\n",
        "\n",
        "    x = tf.concat([lookback, target, lookahead])\n",
        "\n",
        "    x = tf.Dense(\n",
        "        num_outputs,\n",
        "        activation=\"softmax\" if num_outputs > 1 else \"sigmoid\",\n",
        "    )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[lookback_input, target_input, lookahead_input], outputs=x)\n",
        "    return model\n",
        "\n",
        "temporal_model = build_temporal_model(64, 16, 3)\n",
        "tf.keras.utils.plot(temporal_model)"
      ],
      "metadata": {
        "id": "MGMnl6GJQFUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "9OymIyqazQe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng()\n",
        "\n",
        "size = 50\n",
        "data_A = rng.normal(0, 1, (size, HEIGHT, WIDTH, NUM_INPUTS))\n",
        "data_B = rng.normal(0, 1, (size, HEIGHT, WIDTH, NUM_INPUTS))\n",
        "\n",
        "labels = tf.one_hot(rng.integers(0, NUM_OUTPUTS, (size, HEIGHT, WIDTH)), NUM_OUTPUTS)"
      ],
      "metadata": {
        "id": "UNfBGSMXzTiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint to save progress during training and for easier loading of the\n",
        "# model later on, but need to use model.save(...) for EEification\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=f\"{MODEL_DIR}/test/checkpoint\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint],\n",
        ")\n",
        "# model.load_weights(f\"{MODEL_DIR}/test/checkpoint\")\n",
        "model.save(f\"{MODEL_DIR}/test/full_model/\", save_format='tf')"
      ],
      "metadata": {
        "id": "B4yd3MWp1aDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization\n"
      ],
      "metadata": {
        "id": "uoLJqiUwoJ9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_colours = [\"white\", \"black\", \"gold\", \"darkCyan\", \"darkOrange\", \"red\",\n",
        "                 \"orchid\", \"purple\", \"cornsilk\", \"dimGrey\"]\n",
        "CLASS_LIST = [\"None\", \"Non-Forest\", \"Forest\", \"Water\", \"Previous Burn\",\n",
        "              \"Burn\", \"Previous Harvest\", \"Harvest\", \"Cloud\", \"Cloud Shadow\"]\n",
        "cmap = ListedColormap(class_colours, NUM_OUTPUTS)\n",
        "norm = BoundaryNorm(np.arange(NUM_OUTPUTS + 1), NUM_OUTPUTS)"
      ],
      "metadata": {
        "id": "EcqBZ3UnZPQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to verify that the cropping does what we expect\n",
        "def _plot_x(x, axes, i, j):\n",
        "    x = tf.gather(x, (0, 1, 2), axis=-1)\n",
        "    std = np.std(x)\n",
        "    vmin = np.mean(x) - std\n",
        "    vmax = np.mean(x) + std\n",
        "    axes[i, j].imshow(x, vmin=vmin, vmax=vmax)\n",
        "\n",
        "def _plot_y(y, axes, i, j):\n",
        "    y = np.squeeze(np.argmax(y, axis=-1))\n",
        "    axes[i, j].imshow(y, cmap=cmap, norm=norm)\n",
        "\n",
        "def crop_visualizer(pattern, count=10, deterministic_crop=False):\n",
        "    files = tf.data.Dataset.list_files(pattern, shuffle=False)\n",
        "    raw_dataset = tf.data.TFRecordDataset(files, compression_type='GZIP')\n",
        "    dataset = raw_dataset.map(parse)\n",
        "    dataset = dataset.cache()\n",
        "\n",
        "    size = 6\n",
        "    rgb_indices = (0, 1, 2)\n",
        "\n",
        "    if deterministic_crop:\n",
        "        cropped_dataset = dataset.flat_map(non_overlapping_crop)\n",
        "        cropped_dataset = cropped_dataset.take(4 * count)\n",
        "        fig, axes = plt.subplots(count, 10, figsize=(10 * size, count * size))\n",
        "    else:\n",
        "        cropped_dataset = dataset.map(crop_wrapper)\n",
        "        cropped_dataset = cropped_dataset.take(count)\n",
        "        fig, axes = plt.subplots(count, 4, figsize=(4 * size, count * size))\n",
        "\n",
        "    dataset = dataset.take(count)\n",
        "\n",
        "    if deterministic_crop:\n",
        "        for i, (x, y) in enumerate(dataset):\n",
        "            if TWO_DOWNSTACKS:\n",
        "                x = x[0]\n",
        "            _plot_x(x, axes, i, 0)\n",
        "            _plot_y(y, axes, i, 5)\n",
        "\n",
        "        for i, (x, y) in enumerate(cropped_dataset):\n",
        "            if TWO_DOWNSTACKS:\n",
        "                x = x[0]\n",
        "            _plot_x(x, axes, i // 4, 1 + (i % 4))\n",
        "            _plot_y(y, axes, i // 4, 6 + (i % 4))\n",
        "    else:\n",
        "        for i, (x, y) in enumerate(dataset):\n",
        "            if TWO_DOWNSTACKS:\n",
        "                x = x[0]\n",
        "            _plot_x(x, axes, i, 0)\n",
        "            _plot_y(y, axes, i, 2)\n",
        "\n",
        "        for i, (x, y) in enumerate(cropped_dataset):\n",
        "            if TWO_DOWNSTACKS:\n",
        "                x = x[0]\n",
        "            _plot_x(x, axes, i, 1)\n",
        "            _plot_y(y, axes, i, 3)\n",
        "\n",
        "# crop_visualizer(TRAIN_PATTERN, deterministic_crop=True)\n",
        "# crop_visualizer(TRAIN_PATTERN, deterministic_crop=False)"
      ],
      "metadata": {
        "id": "agchBqbDUn-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizer(dataset, model=None, count=10):\n",
        "    rgb_indices = [0, 1, 2]\n",
        "    historical_rgb_indices = [6, 7, 8]\n",
        "\n",
        "    data = dataset.unbatch()\n",
        "\n",
        "    num = 3 if model is None else 4\n",
        "    size = 10\n",
        "    fig, axes = plt.subplots(count, num, figsize=(num * size, count * size))\n",
        "\n",
        "    def plot_row(x, hx, y, model_output, index):\n",
        "        vmin_x = np.mean(x) - (0.5 * np.std(x))\n",
        "        vmax_x = np.mean(x) + (0.5 * np.std(x))\n",
        "        vmin_hx = np.mean(hx) - (0.5 * np.std(hx))\n",
        "        vmax_hx = np.mean(hx) + (0.5 * np.std(hx))\n",
        "        axes[index, 0].imshow(hx, vmin=vmin_hx, vmax=vmax_hx)\n",
        "        axes[index, 1].imshow(x, vmin=vmin_x, vmax=vmax_x)\n",
        "        y = np.argmax(y, axis=-1)\n",
        "        axes[index, 2].imshow(y, cmap=cmap, norm=norm)\n",
        "        if model_output is not None:\n",
        "            model_output = np.squeeze(np.argmax(model_output, axis=-1))\n",
        "            axes[index, 3].imshow(model_output, cmap=cmap, norm=norm)\n",
        "\n",
        "    for i, (x, y) in enumerate(data.take(count)):\n",
        "        if INCLUDE_METADATA:\n",
        "            _x = tf.expand_dims(x[0], axis=0)\n",
        "            metadata = [tf.expand_dims(m, axis=0) for m in x[1:]]\n",
        "            _x = [_x, *metadata]\n",
        "        else:\n",
        "            _x = tf.expand_dims(x, axis=0)\n",
        "\n",
        "        model_output = None if model is None else model(_x)\n",
        "\n",
        "        if INCLUDE_METADATA:\n",
        "            x = x[0]\n",
        "\n",
        "        x_rgb = tf.gather(x, rgb_indices, axis=-1)\n",
        "        hx_rgb = tf.gather(x, historical_rgb_indices, axis=-1)\n",
        "\n",
        "        plot_row(x_rgb, hx_rgb, y, model_output, i)\n",
        "\n",
        "\n",
        "visualizer(train_dataset, model=None, count=25)"
      ],
      "metadata": {
        "id": "UHCVQ_b0ZMEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessment"
      ],
      "metadata": {
        "id": "DYUHQs_lIE8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assess():\n",
        "    pass"
      ],
      "metadata": {
        "id": "PmX1y2XBIH8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEification\n",
        "\n",
        "See https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_TensorFlow_AI_Platform.ipynb"
      ],
      "metadata": {
        "id": "wpUn0e7niLzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "bmEyy8xp-vQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_graph_def = saved_model_utils.get_meta_graph_def(f\"{MODEL_DIR}/test/full_model/\", 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "input_dims = {k: len(v.tensor_shape.dim) - 1 for k, v in inputs.items()}\n",
        "array_input = [k for k in input_dims.keys() if input_dims[k] == 3][0]\n",
        "scalar_inputs = [k for k in input_dims.keys() if input_dims[k] == 1]\n",
        "scalar_inputs.sort(key=lambda name: int(name.split(\"_\")[-1]))\n",
        "input_dict = {inputs[k].name: METADATA[i] for i, k in enumerate(scalar_inputs)}\n",
        "input_dict[inputs[array_input].name] = \"array\"\n",
        "input_dict = \"'\" + json.dumps(input_dict) + \"'\"\n",
        "\n",
        "output_name = None\n",
        "for k, v in outputs.items():\n",
        "    output_name = v.name\n",
        "output_dict = \"'\" + json.dumps({output_name: \"class\"}) + \"'\"\n",
        "\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "id": "vgrd9t_-iO4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f\"{MODEL_DIR}/test/full_model/\"\n",
        "!earthengine set_project {PROJECT_ID}\n",
        "!earthengine model prepare \\\n",
        "    --source_dir {model_path} \\\n",
        "    --dest_dir {EEIFIED_DIR} \\\n",
        "    --input {input_dict} \\\n",
        "    --output {output_dict}"
      ],
      "metadata": {
        "id": "R5vJR2mljCHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gcloud ai-platform models create {MODEL_NAME} \\\n",
        "#     --project {PROJECT_ID} \\\n",
        "#     --region {REGION}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "    --project {PROJECT_ID} \\\n",
        "    --region {REGION} \\\n",
        "    --model {MODEL_NAME} \\\n",
        "    --origin {EEIFIED_DIR} \\\n",
        "    --framework \"TENSORFLOW\" \\\n",
        "    --runtime-version=2.11 \\\n",
        "    --python-version=3.7"
      ],
      "metadata": {
        "id": "mFlOXOXojicT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO\n",
        "* set up assessment code\n",
        "* grid creation\n",
        "    * simplify grid creation code in data.py\n",
        "    * move train/test/val split and large disturbance/small disturbance code to data.py\n",
        "    * ensure that large/small disturbance code doesn't introduce duplicate cells\n",
        "* __not enough disturbances in exported data__\n",
        "* Add Digital Elevation Model band back to export\n",
        "* Add index to distinguish new harvest from old harvest\n",
        "    * red / ndvi\n",
        "    * need way to prove/argue that this is a useful spectral index\n",
        "* Add index to distinguish new burn scar from old burn scar\n",
        "* More data augmentation\n",
        "    * random flips\n",
        "    * random rotations\n",
        "    * random colour/brightness adjustments\n",
        "* temporal model\n",
        "    * write code\n",
        "    * figure out how to export training data\n",
        "* Try out larger node size in AI Platform to see if we can use a larger patch size\n",
        "* Figure out how to run colab with a paid backend\n"
      ],
      "metadata": {
        "id": "KkQ0d_Q7eMhI"
      }
    }
  ]
}