{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPlNi15F2969w8XetCb5wI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/canadaMSSForestDisturbances/blob/main/exportTrainingData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on https://github.com/GoogleCloudPlatform/python-docs-samples/tree/main/people-and-planet-ai/land-cover-classification\n",
        "and https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_training_patches_computePixels.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "wp5BcY0jdj89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "lHfGEmw8-PKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade pip\n",
        "!pip install --quiet \"apache-beam[gcp]==2.46.0\"\n",
        "\n",
        "exit() # restart runtime to ensure we get the newly installed packages"
      ],
      "metadata": {
        "id": "znBYs0werBFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMPH5MSEaA9_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import google\n",
        "from google.colab import auth\n",
        "from google.api_core import retry\n",
        "\n",
        "import requests\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "import ee\n",
        "import geopandas\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT = 'api-project-269347469410'\n",
        "BUCKET = 'gs://rylan-mssforestdisturbances/'\n",
        "LOCATION = 'us-central1'\n",
        "\n",
        "HIGH_VOLUME_ENDPOINT = 'https://earthengine-highvolume.googleapis.com'\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT\n",
        "!gcloud config set project {PROJECT}\n",
        "\n",
        "credentials, _ = google.auth.default()\n",
        "ee.Initialize(credentials, project=PROJECT, opt_url=HIGH_VOLUME_ENDPOINT)"
      ],
      "metadata": {
        "id": "tC8CmOUDa_sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone and install msslib\n",
        "!git clone --quiet https://github.com/boothmanrylan/msslib.git\n",
        "%cd msslib\n",
        "!pip install --quiet .\n",
        "%cd ..\n",
        "\n",
        "!git clone --quiet https://github.com/boothmanrylan/canadaMSSForestDisturbances.git\n",
        "%cd canadaMSSForestDisturbances\n",
        "from mss_forest_disturbances import data"
      ],
      "metadata": {
        "id": "h8n3VuivE2Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = os.path.join(BUCKET, \"data\", \"train_cells.geojson\")\n",
        "train_cells = geopandas.read_file(train_file)"
      ],
      "metadata": {
        "id": "wScp1SmNr5rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_REQUESTS = 20"
      ],
      "metadata": {
        "id": "p2xpItp-hIeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export"
      ],
      "metadata": {
        "id": "xasxeHE6-S9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ECOZONES = [4, 5, 6, 7, 9, 11, 12, 13, 14, 15]\n",
        "DISTURBANCE_TPYES = ['fire', 'harvest', 'undisturbed']\n",
        "\n",
        "def get_image_label_metadata(series):\n",
        "    \"\"\"\n",
        "    row should be a pandas series with keys:\n",
        "    lat, lon, year, ecozone, train/test/val, and fire/harvest/no disturbance\n",
        "    \"\"\"\n",
        "    # TODO: use lat, lon, and year as inputs to msslib.getCol()\n",
        "\n",
        "    # TODO: must return an iterable in order for FlatMap to work: use yield\n",
        "    pass\n",
        "\n",
        "\n",
        "def serialize_tensor(image, label, metadata):\n",
        "    # TODO: create a tf.train.Example()\n",
        "    # TODO: return example.SerializeToString() --> ensure we can read/parse this later on\n",
        "    pass\n",
        "\n",
        "class ProcessSampleGroup(beam.PTransform):\n",
        "    def __init__(self, prefix):\n",
        "        super().__init__()\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | beam.Reshuffle()\n",
        "            | beam.FlatMap(get_image_label_metadata)\n",
        "            | beam.MapTuple(serialize_to_tensor)\n",
        "            | beam.io.WriteToTFRecord(self.prefix, file_name_suffix=\".tfrecord.gz\")\n",
        "        )\n",
        "\n",
        "def filter(x, ecozone, disturbance_type):\n",
        "    x['ecozone'] == ecozone and x['disturbance_type'] == disturbance_type\n",
        "\n",
        "def write_tfrecord(input_file, output_prefix):\n",
        "    data = pd.read_csv(input_file) # TODO: GeoJSON\n",
        "\n",
        "    with beam.Pipeline() as pipeline:\n",
        "        pcoll = pipeline | beam.Create(data)\n",
        "\n",
        "        for ecozone in ECOZONES:\n",
        "            for disturbance_type in DISTURBANCE_TYPES:\n",
        "                path = os.path.join(\n",
        "                    output_prefix,\n",
        "                    f\"ecozone{ecozone}\",\n",
        "                    disturbance_type\n",
        "                )\n",
        "\n",
        "                inner_pcoll = pcoll | beam.Filter(\n",
        "                    lambda x: filter(x, ecozone, disturbance_type)\n",
        "                )\n",
        "                inner_pcoll.apply(ProcessSampleGroup(prefix=path))"
      ],
      "metadata": {
        "id": "gr9Jn2TEbZlT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}