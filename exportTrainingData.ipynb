{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNL1Pgd/Np6hsvktR7I4KkP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boothmanrylan/canadaMSSForestDisturbances/blob/main/exportTrainingData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "lHfGEmw8-PKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "UHuSQFE_TMlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade pip\n",
        "!pip install --quiet \"apache-beam[gcp]==2.46.0\"\n",
        "!pip install --quiet geemap"
      ],
      "metadata": {
        "id": "znBYs0werBFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMPH5MSEaA9_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import google\n",
        "from google.colab import auth\n",
        "from google.api_core import retry\n",
        "\n",
        "import requests\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "import ee\n",
        "import geemap\n",
        "import geopandas\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT = 'api-project-269347469410'\n",
        "BUCKET = 'gs://rylan-mssforestdisturbances/'\n",
        "LOCATION = 'us-central1'\n",
        "\n",
        "HIGH_VOLUME_ENDPOINT = 'https://earthengine-highvolume.googleapis.com'\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT\n",
        "!gcloud config set project {PROJECT}\n",
        "\n",
        "credentials, _ = google.auth.default()\n",
        "ee.Initialize(credentials, project=PROJECT, opt_url=HIGH_VOLUME_ENDPOINT)"
      ],
      "metadata": {
        "id": "tC8CmOUDa_sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone and install msslib\n",
        "!git clone --quiet https://github.com/boothmanrylan/msslib.git\n",
        "%cd msslib\n",
        "!pip install --quiet .\n",
        "%cd ..\n",
        "\n",
        "!git clone --quiet https://github.com/boothmanrylan/canadaMSSForestDisturbances.git\n",
        "%cd canadaMSSForestDisturbances\n",
        "from mss_forest_disturbances import data"
      ],
      "metadata": {
        "id": "h8n3VuivE2Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_REQUESTS = 20\n",
        "ASSET_PATH = \"projects/api-project-269347469410/assets/rylan-mssforestdisturbances/\""
      ],
      "metadata": {
        "id": "p2xpItp-hIeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Create a Covering Grid of Forest Dominated Canada"
      ],
      "metadata": {
        "id": "gR7Ys8nCJtAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1.1\n",
        "\n",
        "Create a grid that covers all of forest dominated Canada, excluding cells that are >70% water. Export the resulting grid as an Earth Engine asset."
      ],
      "metadata": {
        "id": "Lrjolqzxe-4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_CELL_SIZE = 512\n",
        "grid = data.build_land_covering_grid(data.ECOZONES.geometry(), GRID_CELL_SIZE)\n",
        "grid_list = grid.toList(grid.size())\n",
        "ids = ee.List.sequence(0, grid.size().subtract(1))\n",
        "id_grid = ee.FeatureCollection(\n",
        "    ids.map(lambda i: ee.Feature(grid_list.get(i)).set('cell_id', i))\n",
        ")\n",
        "\n",
        "task = ee.batch.Export.table.toAsset(\n",
        "    collection=id_grid,\n",
        "    description=\"export_land_covering_grid\",\n",
        "    assetId=os.path.join(ASSET_PATH, \"data\", \"land_covering_grid\")\n",
        ")\n",
        "task.start()"
      ],
      "metadata": {
        "id": "tOXzAry5J1qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1.2\n",
        "\n",
        "For each year for which we are generating training data estimate the amount of harvest and fire that occurred in each cell of the grid created in Step 1.1. Export the resulting FeatureCollection as an Earth Engine asset."
      ],
      "metadata": {
        "id": "I9BgkkWxeqiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_id(feature):\n",
        "    cell_id = ee.String(feature.getNumber(\"cell_id\"))\n",
        "    year = ee.String(feature.getNumber(\"year\"))\n",
        "    id = cell_id.cat(\"_\").cat(year)\n",
        "    return feature.set(\"id\", cell_id)\n",
        "\n",
        "base_grid = ee.FeatureCollection(os.path.join(ASSET_PATH, \"data\", \"land_covering_grid\"))\n",
        "\n",
        "for year in range(1985, 1996):\n",
        "    annual_grid = data.add_disturbance_counts(base_grid, year).map(set_id)\n",
        "\n",
        "    asset_name = f\"disturbance_estimate_grid_{year}\"\n",
        "    task = ee.batch.Export.table.toAsset(\n",
        "        collection=annual_grid,\n",
        "        description=f\"export_grid_with_disturbance_estimates_{year}\",\n",
        "        assetId=os.path.join(ASSET_PATH, \"data\", asset_name)\n",
        "    )\n",
        "    task.start()"
      ],
      "metadata": {
        "id": "eQoIBRFYX_Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Select Cells from Grid to Create Train/Test/Val Datasets"
      ],
      "metadata": {
        "id": "_eBdlxYZJ2zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annual_grids_assets = [\n",
        "    os.path.join(ASSET_PATH, \"data\", f\"disturbance_estimate_grid_{year}\")\n",
        "    for year in range(1985, 1996)\n",
        "]\n",
        "annual_grids = ee.FeatureCollection([\n",
        "    ee.FeatureCollection(asset)\n",
        "    for asset in annual_grids_assets\n",
        "]).flatten()\n",
        "\n",
        "# perform the train/test/val splitting individually within each ecozone\n",
        "ecozones = annual_grids.aggregate_array(\"ecozone\").distinct().getInfo()\n",
        "ecozone_grids = [\n",
        "    annual_grids.filter(ee.Filter.eq(\"ecozone\", x))\n",
        "    for x in ecozones\n",
        "]\n",
        "\n",
        "cell_counts = [200, 200, 200]\n",
        "splits = [0.7, 0.15, 0.15]\n",
        "selected_cells = [\n",
        "    data.sample_cells(grid, *cell_counts, *splits)\n",
        "    for grid in ecozone_grids\n",
        "]\n",
        "\n",
        "# join the train/test/val groups from each ecozone\n",
        "# shuffle to ensure ecozones are intermingled\n",
        "train_cells = ee.FeatureCollection(\n",
        "    [ecozone_selection[0] for ecozone_selection in selected_cells]\n",
        ").flatten().sort(\"shuffle\")\n",
        "test_cells = ee.FeatureCollection(\n",
        "    [ecozone_selection[1] for ecozone_selection in selected_cells]\n",
        ").flatten().sort(\"shuffle\")\n",
        "val_cells = ee.FeatureCollection(\n",
        "    [ecozone_selection[2] for ecozone_selection in selected_cells]\n",
        ").flatten().sort(\"shuffle\")\n",
        "\n",
        "# export each group to Google Earth Engine\n",
        "task = ee.batch.Export.table.toAsset(\n",
        "    collection=train_cells,\n",
        "    description=\"export_train_cells\",\n",
        "    assetId=os.path.join(ASSET_PATH, \"data\", \"train_cells\")\n",
        ")\n",
        "task.start()\n",
        "\n",
        "task = ee.batch.Export.table.toAsset(\n",
        "    collection=test_cells,\n",
        "    description=\"export_test_cells\",\n",
        "    assetId=os.path.join(ASSET_PATH, \"data\", \"test_cells\")\n",
        ")\n",
        "task.start()\n",
        "\n",
        "task = ee.batch.Export.table.toAsset(\n",
        "    collection=val_cells,\n",
        "    description=\"export_val_cells\",\n",
        "    assetId=os.path.join(ASSET_PATH, \"data\", \"val_cells\")\n",
        ")\n",
        "task.start()"
      ],
      "metadata": {
        "id": "8A-YfrW3pce_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Export Image Patches\n",
        "\n",
        "Based on https://github.com/GoogleCloudPlatform/python-docs-samples/tree/main/people-and-planet-ai/land-cover-classification\n",
        "and https://github.com/google/earthengine-community/blob/master/guides/linked/Earth_Engine_training_patches_computePixels.ipynb"
      ],
      "metadata": {
        "id": "xasxeHE6-S9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = os.path.join(BUCKET, \"data\", \"train_cells.geojson\")\n",
        "train_cells = geopandas.read_file(train_file)\n",
        "# train_cells = train_cells.to_crs(data.PROJECTION.getInfo()['wkt'])"
      ],
      "metadata": {
        "id": "wScp1SmNr5rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell = None\n",
        "for index, c in train_cells.iterrows():\n",
        "    cell = c\n",
        "    break\n",
        "type(cell)"
      ],
      "metadata": {
        "id": "s_P-lYBHsjNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geom = ee.Geometry.Polygon(list(cell[\"geometry\"].exterior.coords))\n",
        "print(geom.projection().getInfo())\n",
        "Map = geemap.Map()\n",
        "Map.centerObject(geom)\n",
        "Map.addLayer(geom, {}, \"Test Geometry\")\n",
        "Map"
      ],
      "metadata": {
        "id": "KXzLKiRrtVzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.PROJECTION.getInfo()['wkt'])\n",
        "test_set_crs = train_cells.to_crs(data.PROJECTION.getInfo()['wkt'])\n",
        "print(test_set_crs.crs)"
      ],
      "metadata": {
        "id": "ykCrpavRwGc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzUCNhUkvB_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ECOZONES = [4, 5, 6, 7, 9, 11, 12, 13, 14, 15]\n",
        "DISTURBANCE_TYPES = ['fire', 'harvest', 'undisturbed']\n",
        "\n",
        "def get_image_label_metadata(series):\n",
        "    \"\"\"\n",
        "    row should be a pandas series with keys:\n",
        "    lat, lon, year, ecozone, train/test/val, and fire/harvest/no disturbance\n",
        "    \"\"\"\n",
        "    # TODO: use lat, lon, and year as inputs to msslib.getCol()\n",
        "\n",
        "    # TODO: must return an iterable in order for FlatMap to work: use yield\n",
        "    pass\n",
        "\n",
        "\n",
        "def serialize_tensor(image, label, metadata):\n",
        "    # TODO: create a tf.train.Example()\n",
        "    # TODO: return example.SerializeToString() --> ensure we can read/parse this later on\n",
        "    pass\n",
        "\n",
        "class ProcessSampleGroup(beam.PTransform):\n",
        "    def __init__(self, prefix):\n",
        "        super().__init__()\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | beam.FlatMap(get_image_label_metadata)\n",
        "            | beam.MapTuple(serialize_tensor)\n",
        "            | beam.io.WriteToTFRecord(self.prefix, file_name_suffix=\".tfrecord.gz\")\n",
        "        )\n",
        "\n",
        "def filter(x, ecozone, disturbance_type):\n",
        "    x['ecozone'] == ecozone and x['disturbance_type'] == disturbance_type\n",
        "\n",
        "def write_tfrecord(input_file, output_prefix):\n",
        "    data = pd.read_csv(input_file) # TODO: GeoJSON\n",
        "\n",
        "    with beam.Pipeline() as pipeline:\n",
        "        pcoll = pipeline | beam.Create(data) | beam.Reshuffle()\n",
        "\n",
        "        for ecozone in ECOZONES:\n",
        "            for disturbance_type in DISTURBANCE_TYPES:\n",
        "                path = os.path.join(\n",
        "                    output_prefix,\n",
        "                    f\"ecozone{ecozone}\",\n",
        "                    disturbance_type\n",
        "                )\n",
        "\n",
        "                inner_pcoll = pcoll | beam.Filter(\n",
        "                    lambda x: filter(x, ecozone, disturbance_type)\n",
        "                )\n",
        "                inner_pcoll.apply(ProcessSampleGroup(prefix=path))"
      ],
      "metadata": {
        "id": "gr9Jn2TEbZlT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}